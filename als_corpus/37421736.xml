<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">37421736</PMID><DateCompleted><Year>2023</Year><Month>08</Month><Day>21</Day></DateCompleted><DateRevised><Year>2023</Year><Month>08</Month><Day>24</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1879-0534</ISSN><JournalIssue CitedMedium="Internet"><Volume>163</Volume><PubDate><Year>2023</Year><Month>Sep</Month></PubDate></JournalIssue><Title>Computers in biology and medicine</Title><ISOAbbreviation>Comput Biol Med</ISOAbbreviation></Journal><ArticleTitle>A store-and-forward cloud-based telemonitoring system for automatic assessing dysarthria evolution in neurological diseases from video-recording analysis.</ArticleTitle><Pagination><StartPage>107194</StartPage><MedlinePgn>107194</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1016/j.compbiomed.2023.107194</ELocationID><ELocationID EIdType="pii" ValidYN="Y">S0010-4825(23)00659-5</ELocationID><Abstract><AbstractText Label="BACKGROUND AND OBJECTIVES">Patients suffering from neurological diseases may develop dysarthria, a motor speech disorder affecting the execution of speech. Close and quantitative monitoring of dysarthria evolution is crucial for enabling clinicians to promptly implement patients' management strategies and maximizing effectiveness and efficiency of communication functions in term of restoring, compensating or adjusting. In the clinical assessment of orofacial structures and functions, at rest condition or during speech and non-speech movements, a qualitative evaluation is usually performed, throughout visual observation.</AbstractText><AbstractText Label="METHODS">To overcome limitations posed by qualitative assessments, this work presents a store-and-forward self-service telemonitoring system that integrates, within its cloud architecture, a convolutional neural network (CNN) for analyzing video recordings acquired by individuals with dysarthria. This architecture - called facial landmark Mask RCNN - aims at locating facial landmarks as a prior for assessing the orofacial functions related to speech and examining dysarthria evolution in neurological diseases.</AbstractText><AbstractText Label="RESULTS">When tested on the Toronto NeuroFace dataset, a publicly available annotated dataset of video recordings from patients with amyotrophic lateral sclerosis (ALS) and stroke, the proposed CNN achieved a normalized mean error equal to 1.79 on localizing the facial landmarks. We also tested our system in a real-life scenario on 11 bulbar-onset ALS subjects, obtaining promising outcomes in terms of facial landmark position estimation.</AbstractText><AbstractText Label="DISCUSSION AND CONCLUSIONS">This preliminary study represents a relevant step towards the use of remote tools to support clinicians in monitoring the evolution of dysarthria.</AbstractText><CopyrightInformation>Copyright &#xa9; 2023 Elsevier Ltd. All rights reserved.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Migliorelli</LastName><ForeName>Lucia</ForeName><Initials>L</Initials><AffiliationInfo><Affiliation>Department of Information Engineering, Univerist&#xe0; Politecnica Delle Marche, Via Brecce Bianche 12, Ancona, 60121, Italy; AIDAPT S.r.l, Via Brecce Bianche 12, Ancona, 60121, Italy. Electronic address: l.migliorelli@univpm.it.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Berardini</LastName><ForeName>Daniele</ForeName><Initials>D</Initials><AffiliationInfo><Affiliation>Department of Information Engineering, Univerist&#xe0; Politecnica Delle Marche, Via Brecce Bianche 12, Ancona, 60121, Italy. Electronic address: d.berardini@pm.univpm.it.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Cela</LastName><ForeName>Kevin</ForeName><Initials>K</Initials><AffiliationInfo><Affiliation>Department of Information Engineering, Univerist&#xe0; Politecnica Delle Marche, Via Brecce Bianche 12, Ancona, 60121, Italy; AIDAPT S.r.l, Via Brecce Bianche 12, Ancona, 60121, Italy. Electronic address: kevin.cela@aidaptsrl.com.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Coccia</LastName><ForeName>Michela</ForeName><Initials>M</Initials><AffiliationInfo><Affiliation>Centro Clinico NeuroMuscular Omnicentre (NeMO), Fondazione Serena Onlus, Via Conca 71, Torrette (Ancona), 60126, Italy. Electronic address: michela.coccia@centrocliniconemo.it.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Villani</LastName><ForeName>Laura</ForeName><Initials>L</Initials><AffiliationInfo><Affiliation>Department of Neuroscience, Neurorehabilitation Clinic, Azienda Ospedaliero-Universitaria delle Marche, Via Conca 71, Torrette (Ancona), 60126, Italy. Electronic address: laura.villani@ospedaliriuniti.marche.it.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Frontoni</LastName><ForeName>Emanuele</ForeName><Initials>E</Initials><AffiliationInfo><Affiliation>AIDAPT S.r.l, Via Brecce Bianche 12, Ancona, 60121, Italy; Department of Political Sciences, Communication, and International Relations, Universit&#xe0; Degli Studi di Macerata, Via Giovanni Mario Crescimbeni 30, Macerata, 62100, Italy; NeMO Lab, Piazza dell'Ospedale Maggiore, Milano, 20162, Italy. Electronic address: emanuele.frontoni@unimc.it.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Moccia</LastName><ForeName>Sara</ForeName><Initials>S</Initials><AffiliationInfo><Affiliation>The BioRobotics Institute, Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Piazza Martiri della Libert&#xe0;, 33, Pisa, 56127, Italy. Electronic address: sara.moccia@santannapisa.it.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2023</Year><Month>06</Month><Day>30</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>Comput Biol Med</MedlineTA><NlmUniqueID>1250250</NlmUniqueID><ISSNLinking>0010-4825</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D004401" MajorTopicYN="Y">Dysarthria</DescriptorName><QualifierName UI="Q000175" MajorTopicYN="N">diagnosis</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="Y">Amyotrophic Lateral Sclerosis</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000067917" MajorTopicYN="N">Cloud Computing</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013060" MajorTopicYN="N">Speech</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D014741" MajorTopicYN="N">Video Recording</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">Deep learning</Keyword><Keyword MajorTopicYN="N">Dysarthria</Keyword><Keyword MajorTopicYN="N">Facial-landmark detection</Keyword><Keyword MajorTopicYN="N">Store-and-forward telemonitoring</Keyword></KeywordList><CoiStatement>Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2023</Year><Month>3</Month><Day>21</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2023</Year><Month>6</Month><Day>6</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2023</Year><Month>6</Month><Day>19</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2023</Year><Month>8</Month><Day>21</Day><Hour>6</Hour><Minute>41</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2023</Year><Month>7</Month><Day>9</Day><Hour>1</Hour><Minute>7</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2023</Year><Month>7</Month><Day>8</Day><Hour>18</Hour><Minute>2</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">37421736</ArticleId><ArticleId IdType="doi">10.1016/j.compbiomed.2023.107194</ArticleId><ArticleId IdType="pii">S0010-4825(23)00659-5</ArticleId></ArticleIdList></PubmedData></PubmedArticle></PubmedArticleSet>