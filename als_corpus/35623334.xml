<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">35623334</PMID><DateCompleted><Year>2022</Year><Month>06</Month><Day>10</Day></DateCompleted><DateRevised><Year>2022</Year><Month>12</Month><Day>02</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1558-9102</ISSN><JournalIssue CitedMedium="Internet"><Volume>65</Volume><Issue>6</Issue><PubDate><Year>2022</Year><Month>Jun</Month><Day>08</Day></PubDate></JournalIssue><Title>Journal of speech, language, and hearing research : JSLHR</Title><ISOAbbreviation>J Speech Lang Hear Res</ISOAbbreviation></Journal><ArticleTitle>Validity of Off-the-Shelf Automatic Speech Recognition for Assessing Speech Intelligibility and Speech Severity in Speakers With Amyotrophic Lateral Sclerosis.</ArticleTitle><Pagination><StartPage>2128</StartPage><EndPage>2143</EndPage><MedlinePgn>2128-2143</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1044/2022_JSLHR-21-00589</ELocationID><Abstract><AbstractText Label="PURPOSE">There is increasing interest in using automatic speech recognition (ASR) systems to evaluate impairment severity or speech intelligibility in speakers with dysarthria. We assessed the clinical validity of one currently available off-the-shelf (OTS) ASR system (i.e., a Google Cloud ASR API) for indexing sentence-level speech intelligibility and impairment severity in individuals with amyotrophic lateral sclerosis (ALS), and we provided guidance for potential users of such systems in research and clinic.</AbstractText><AbstractText Label="METHOD">Using speech samples collected from 52 individuals with ALS and 20 healthy control speakers, we compared word recognition rate (WRR) from the commercially available Google Cloud ASR API (Machine WRR) to clinician-provided judgments of impairment severity, as well as sentence intelligibility (Human WRR). We assessed the internal reliability of Machine and Human WRR by comparing the standard deviation of WRR across sentences to the minimally detectable change (MDC), a clinical benchmark that indicates whether results are within measurement error. We also evaluated Machine and Human WRR diagnostic accuracy for classifying speakers into clinically established categories.</AbstractText><AbstractText Label="RESULTS">Human WRR achieved better accuracy than Machine WRR when indexing speech severity, and, although related, Human and Machine WRR were not strongly correlated. When the speech signal was mixed with noise (noise-augmented ASR) to reduce a ceiling effect, Machine WRR performance improved. Internal reliability metrics were worse for Machine than Human WRR, particularly for typical and mildly impaired severity groups, although sentence length significantly impacted both Machine and Human WRRs.</AbstractText><AbstractText Label="CONCLUSIONS">Results indicated that the OTS ASR system was inadequate for early detection of speech impairment and grading overall speech severity. While Machine and Human WRR were correlated, ASR should not be used as a one-to-one proxy for transcription speech intelligibility or clinician severity ratings. Overall, findings suggested that the tested OTS ASR system, Google Cloud ASR, has limited utility for grading clinical speech impairment in speakers with ALS.</AbstractText></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Gutz</LastName><ForeName>Sarah E</ForeName><Initials>SE</Initials><Identifier Source="ORCID">0000-0002-1601-0639</Identifier><AffiliationInfo><Affiliation>Program in Speech and Hearing Bioscience and Technology, Harvard Medical School, Boston, MA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Stipancic</LastName><ForeName>Kaila L</ForeName><Initials>KL</Initials><Identifier Source="ORCID">0000-0001-5185-563X</Identifier><AffiliationInfo><Affiliation>Department of Communicative Disorders and Sciences, University at Buffalo, NY.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Yunusova</LastName><ForeName>Yana</ForeName><Initials>Y</Initials><Identifier Source="ORCID">0000-0002-2353-2275</Identifier><AffiliationInfo><Affiliation>Department of Speech-Language Pathology, University of Toronto, Ontario, Canada.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Hurvitz Brain Sciences Program, Sunnybrook Research Institute, Toronto, Ontario, Canada.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Toronto Rehabilitation Institute, University Health Network, Ontario, Canada.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Berry</LastName><ForeName>James D</ForeName><Initials>JD</Initials><AffiliationInfo><Affiliation>Sean M. Healey and AMG Center for ALS, Massachusetts General Hospital, Boston.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Green</LastName><ForeName>Jordan R</ForeName><Initials>JR</Initials><Identifier Source="ORCID">0000-0002-1464-1373</Identifier><AffiliationInfo><Affiliation>Program in Speech and Hearing Bioscience and Technology, Harvard Medical School, Boston, MA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Communication Sciences and Disorders, MGH Institute of Health Professions, Boston, MA.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><GrantList CompleteYN="Y"><Grant><GrantID>F31 DC019016</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant><Grant><GrantID>K24 DC016312</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant><Grant><GrantID>R01 DC017291</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant><Grant><GrantID>T32 DC000038</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant></GrantList><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType><PublicationType UI="D052061">Research Support, N.I.H., Extramural</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2022</Year><Month>05</Month><Day>27</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>J Speech Lang Hear Res</MedlineTA><NlmUniqueID>9705610</NlmUniqueID><ISSNLinking>1092-4388</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="Y">Amyotrophic Lateral Sclerosis</DescriptorName><QualifierName UI="Q000150" MajorTopicYN="N">complications</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D004401" MajorTopicYN="N">Dysarthria</DescriptorName><QualifierName UI="Q000175" MajorTopicYN="N">diagnosis</QualifierName><QualifierName UI="Q000209" MajorTopicYN="N">etiology</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D015203" MajorTopicYN="N">Reproducibility of Results</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013064" MajorTopicYN="N">Speech Disorders</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013065" MajorTopicYN="N">Speech Intelligibility</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013067" MajorTopicYN="Y">Speech Perception</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013068" MajorTopicYN="N">Speech Production Measurement</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading></MeshHeadingList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="pubmed"><Year>2022</Year><Month>5</Month><Day>28</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2022</Year><Month>6</Month><Day>11</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2022</Year><Month>5</Month><Day>27</Day><Hour>18</Hour><Minute>29</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">35623334</ArticleId><ArticleId IdType="pmc">PMC9567308</ArticleId><ArticleId IdType="doi">10.1044/2022_JSLHR-21-00589</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Allison, K. M. , Yunusova, Y. , Campbell, T. F. , Wang, J. , Berry, J. D. , &amp; Green, J. R. (2017). The diagnostic utility of patient-report and speech-language pathologists' ratings for detecting the early onset of bulbar symptoms due to ALS. Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration, 18(5&#x2013;6), 358&#x2013;366. https://doi.org/10.1080/21678421.2017.1303515</Citation><ArticleIdList><ArticleId IdType="pmc">PMC5530595</ArticleId><ArticleId IdType="pubmed">28355886</ArticleId></ArticleIdList></Reference><Reference><Citation>Allison, K. M. , Yunusova, Y. , &amp; Green, J. R. (2019). Shorter sentence length maximizes intelligibility and speech motor performance in persons with dysarthria due to amyotrophic lateral sclerosis. American Journal of Speech-Language Pathology, 28(1), 96&#x2013;107. https://doi.org/10.1044/2018_AJSLP-18-0049</Citation><ArticleIdList><ArticleId IdType="pmc">PMC6503867</ArticleId><ArticleId IdType="pubmed">31072158</ArticleId></ArticleIdList></Reference><Reference><Citation>Ballard, K. J. , Etter, N. M. , Shen, S. , Monroe, P. , &amp; Tand, C. T. (2019). Feasibility of automatic speech recognition for providing feedback during tablet-based treatment for apraxia of speech plus aphasia. American Journal of Speech-Language Pathology, 28(2S), 818&#x2013;834. https://doi.org/10.1044/2018_AJSLP-MSC18-18-0109</Citation><ArticleIdList><ArticleId IdType="pubmed">31306595</ArticleId></ArticleIdList></Reference><Reference><Citation>Bates, D. , Maechler, M. , Bolker, B. , &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1&#x2013;48. https://doi.org/10.18637/jss.v067.i01</Citation></Reference><Reference><Citation>Benzeghiba, M. , De Mori, R. , Deroo, O. , Dupont, S. , Erbes, T. , Jouvet, D. , Fissore, L. , Laface, P. , Mertins, A. , Ris, C. , Rose, R. , Tyagi, V. , &amp; Wellekens, C. (2007). Automatic speech recognition and speech variability: A review. Speech Communication, 49(10&#x2013;11), 763&#x2013;786. https://doi.org/10.1016/j.specom.2007.02.006</Citation></Reference><Reference><Citation>Blaney, B. , &amp; Hewlett, N. (2007). Dysarthria and Friedreich's ataxia: What can intelligibility assessment tell us? International Journal of Language &amp; Communication Disorders, 42(1), 19&#x2013;37. https://doi.org/10.1080/13682820600690993</Citation><ArticleIdList><ArticleId IdType="pubmed">17365084</ArticleId></ArticleIdList></Reference><Reference><Citation>Cedarbaum, J. M. , Stambler, N. , Malta, E. , Fuller, C. , Hilt, D. , Thurmond, B. , &amp; Nakanishi, A. (1999). The ALSFRS-R: A revised ALS functional rating scale that incorporates assessments of respiratory function. BDNF ALS Study Group (Phase III). Journal of the Neurological Sciences, 169(1&#x2013;2), 13&#x2013;21. https://doi.org/10.1016/S0022-510X(99)00210-5</Citation><ArticleIdList><ArticleId IdType="pubmed">10540002</ArticleId></ArticleIdList></Reference><Reference><Citation>Christensen, H. , Cunningham, S. P. , Fox, C. W. , Green, P. D. , &amp; Hain, T. (2012). A comparative study of adaptive, automatic recognition of disordered speech. Interspeech 2012 Conference Proceedings, 1776&#x2013;1779.</Citation></Reference><Reference><Citation>Connaghan, K. P. , &amp; Patel, R. (2017). The impact of contrastive stress on vowel acoustics and intelligibility in dysarthria. Journal of Speech, Language, and Hearing Research, 60(1), 38&#x2013;50. https://doi.org/10.1044/2016_JSLHR-S-15-0291</Citation><ArticleIdList><ArticleId IdType="pmc">PMC5533559</ArticleId><ArticleId IdType="pubmed">28114612</ArticleId></ArticleIdList></Reference><Reference><Citation>Darley, F. L. , Aronson, A. E. , &amp; Brown, J. R. (1969). Differential diagnostic patterns of dysarthria. Journal of Speech and Hearing Research, 12(2), 246&#x2013;269. https://doi.org/10.1044/jshr.1202.246</Citation><ArticleIdList><ArticleId IdType="pubmed">5808852</ArticleId></ArticleIdList></Reference><Reference><Citation>De Russis, L. , &amp; Corno, F. (2019). On the impact of dysarthric speech on contemporary ASR cloud platforms. Journal of Reliable Intelligent Environments, 5(3), 163&#x2013;172. https://doi.org/10.1007/s40860-019-00085-y</Citation></Reference><Reference><Citation>Dimauro, G. , Di Nicola, V. , Bevilacqua, V. , Caivano, D. , &amp; Girardi, F. (2017). Assessment of speech intelligibility in Parkinson's disease using a speech-to-text system. IEEE Access, 5, 22199&#x2013;22208. https://doi.org/10.1109/ACCESS.2017.2762475</Citation></Reference><Reference><Citation>Enderby, P. (1980). Frenchay dysarthria assessment. British Journal of Disorders of Communication, 15(3), 165&#x2013;173. https://doi.org/10.3109/13682828009112541</Citation></Reference><Reference><Citation>Ferrier, L. J. , Shane, H. C. , Ballard, H. F. , Carpenter, T. , &amp; Benoit, A. (1995). Dysarthric speakers intelligibility and speech characteristics in relation to computer speech recognition. Augmentative and Alternative Communication, 11(3), 165&#x2013;175. https://doi.org/10.1080/07434619512331277289</Citation></Reference><Reference><Citation>Goldsack, J. C. , Coravos, A. , Bakker, J. P. , Bent, B. , Dowling, A. V. , Fitzer-Attas, C. , Godfrey, A. , Godino, J. G. , Gujar, N. , Izmailova, E. , Manta, C. , Peterson, B. , Vandendriessche, B. , Wood, W. A. , Wang, K. W. , &amp; Dunn, J. (2020). Verification, analytical validation, and clinical validation (V3): The foundation of determining fit-for-purpose for Biometric Monitoring Technologies (BioMeTs). npj Digital Medicine, 3(1), 55. https://doi.org/10.1038/s41746-020-0260-4</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7156507</ArticleId><ArticleId IdType="pubmed">32337371</ArticleId></ArticleIdList></Reference><Reference><Citation>Goldwater, S. , Jurafsky, D. , &amp; Manning, C. D. (2010). Which words are hard to recognize? Prosodic, lexical, and disfluency factors that increase speech recognition error rates. Speech Communication, 52(3), 181&#x2013;200. https://doi.org/10.1016/j.specom.2009.10.001</Citation></Reference><Reference><Citation>
Google LLC. (2020). Speech-to-text: Automatic speech recognition, Google Cloud. Retrieved January 18, 2022, from https://cloud.google.com/speech-to-text

</Citation></Reference><Reference><Citation>Green, J. R. , MacDonald, R. L. , Jiang, P.-P. , Cattiau, J. , Heywood, R. , Cave, R. , Seaver, K. , Ladewig, M. A. , Tobin, J. , Brenner, M. P. , Nelson, P. C. , &amp; Tomanek, K. (2021). Automatic speech recognition of disordered speech: Personalized models outperforming human listeners on short phrases. Interspeech 2021 Conference Proceedings, 4778&#x2013;4782. https://doi.org/10.21437/INTERSPEECH.2021-1384</Citation></Reference><Reference><Citation>Green, J. R. , Yunusova, Y. , Kuruvilla, M. S. , Wang, J. , Pattee, G. L. , Synhorst, L. , Zinman, L. , &amp; Berry, J. D. (2013). Bulbar and speech motor assessment in ALS: Challenges and future directions. Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration, 14(7&#x2013;8), 494&#x2013;500. https://doi.org/10.3109/21678421.2013.817585</Citation><ArticleIdList><ArticleId IdType="pmc">PMC3833808</ArticleId><ArticleId IdType="pubmed">23898888</ArticleId></ArticleIdList></Reference><Reference><Citation>Gupta, R. , Chaspari, T. , Kim, J. , Kumar, N. , Bone, D. , &amp; Narayanan, S. (2016). Pathological speech processing: State-of-the-art, current challenges, and future directions. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 6470&#x2013;6474.</Citation></Reference><Reference><Citation>Gutz, S. E. , Rowe, H. P. , &amp; Green, J. R. (2021). Speaking with a KN95 face mask: ASR performance and speaker compensation. Interspeech 2021 Conference Proceedings, 4798&#x2013;4802.</Citation></Reference><Reference><Citation>Gutz, S. E. , Wang, J. , Yunusova, Y. , &amp; Green, J. R. (2019). Early identification of speech changes due to amyotrophic lateral sclerosis using machine classification. Interspeech 2019 Conference Proceedings, 604&#x2013;608. https://doi.org/10.21437/Interspeech.2019-2967</Citation></Reference><Reference><Citation>Harris, P. A. , Taylor, R. , Thielke, R. , Payne, J. , Gonzalez, N. , &amp; Conde, J. G. (2009). Research electronic data capture (REDCap)-A metadata-driven methodology and workflow process for providing translational research informatics support. Journal of Biomedical Informatics, 42(2), 377&#x2013;381. https://doi.org/10.1016/j.jbi.2008.08.010</Citation><ArticleIdList><ArticleId IdType="pmc">PMC2700030</ArticleId><ArticleId IdType="pubmed">18929686</ArticleId></ArticleIdList></Reference><Reference><Citation>Hustad, K. C. (2008). The relationship between listener comprehension and intelligibility scores for speakers with dysarthria. Journal of Speech, Language, and Hearing Research, 51(3), 562&#x2013;573. https://doi.org/10.1044/1092-4388(2008/040)</Citation><ArticleIdList><ArticleId IdType="pmc">PMC3016201</ArticleId><ArticleId IdType="pubmed">18506035</ArticleId></ArticleIdList></Reference><Reference><Citation>Jacks, A. , Haley, K. L. , Bishop, G. , &amp; Harmon, T. G. (2019). Automated speech recognition in adult stroke survivors: Comparing human and computer transcriptions. Folia Phoniatrica et Logopaedica, 71(5&#x2013;6), 286&#x2013;296. https://doi.org/10.1159/000499156</Citation><ArticleIdList><ArticleId IdType="pubmed">31117105</ArticleId></ArticleIdList></Reference><Reference><Citation>Keshet, J. (2018). Automatic speech recognition: A primer for speech-language pathology researchers. International Journal of Speech-Language Pathology, 20(6), 599&#x2013;609. https://doi.org/10.1080/17549507.2018.1510033</Citation><ArticleIdList><ArticleId IdType="pubmed">31274357</ArticleId></ArticleIdList></Reference><Reference><Citation>King, J. M. , Watson, M. , &amp; Lof, G. L. (2012). Practice patterns of speech-language pathologists assessing intelligibility of dysarthric speech. Journal of Medical Speech-Language Pathology, 20(1), 1&#x2013;16.</Citation></Reference><Reference><Citation>Krishna, G. , Tran, C. , Yu, J. , &amp; Tewfik, A. H. (2019). Speech recognition with no speech or with noisy speech. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1090&#x2013;1094). https://doi.org/10.1109/ICASSP.2019.8683453</Citation></Reference><Reference><Citation>Levenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(8), 707&#x2013;710.</Citation></Reference><Reference><Citation>Low, D. M. , Bentley, K. H. , &amp; Ghosh, S. S. (2020). Automated assessment of psychiatric disorders using speech: A systematic review. Laryngoscope Investigative Otolaryngology, 5(1), 96&#x2013;116. https://doi.org/10.1002/LIO2.354</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7042657</ArticleId><ArticleId IdType="pubmed">32128436</ArticleId></ArticleIdList></Reference><Reference><Citation>Maier, A. , Haderlein, T. , Stelzle, F. , N&#xf6;th, E. , Nkenke, E. , Rosanowski, F. , Sch&#xfc;tzenberger, A. , &amp; Schuster, M. (2010). Automatic speech recognition systems for the evaluation of voice and speech disorders in head and neck cancer. EURASIP Journal on Audio, Speech, and Music Processing, 2010(1), Article 24. https://doi.org/10.1186/1687-4722-2010-926951</Citation></Reference><Reference><Citation>
MathWorks Audio Toolbox Team. (2022). 
speech2text. MATLAB Central File Exchange. https://www.mathworks.com/matlabcentral/fileexchange/65266-speech2text
</Citation></Reference><Reference><Citation>McHenry, M. A. , &amp; Laconte, S. (2010). Computer speech recognition as an objective measure of intelligibility. Journal of Medical Speech-Language Pathology, 18(4), 99&#x2013;103.</Citation></Reference><Reference><Citation>Miller, N. (2013). Measuring up to speech intelligibility. International Journal of Language &amp; Communication Disorders, 48(6), 601&#x2013;612. https://doi.org/10.1111/1460-6984.12061</Citation><ArticleIdList><ArticleId IdType="pubmed">24119170</ArticleId></ArticleIdList></Reference><Reference><Citation>
Miracle Ear. (2018). Online hearing test. 
https://www.miracle-ear.com/online-hearing-test

</Citation></Reference><Reference><Citation>Mulholland, M. , Lopez, M. , Evanini, K. , Loukina, A. , &amp; Qian, Y. (2016). A comparison of ASR and human errors for transcription of non-native spontaneous speech. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 5855&#x2013;5859). https://doi.org/10.1109/ICASSP.2016.7472800</Citation></Reference><Reference><Citation>Mustafa, M. B. , Rosdi, F. , Salim, S. S. , &amp; Mughal, U. M. (2015). Exploring the influence of general and specific factors on the recognition accuracy of an ASR system for dysarthric speaker. Expert Systems with Applications, 42(8), 3924&#x2013;3932. https://doi.org/10.1016/j.eswa.2015.01.033</Citation></Reference><Reference><Citation>Park, D. S. , Zhang, Y. , Chiu, C.-C. , Chen, Y. , Li, B. , Chan, W. , Le, Q. V. , &amp; Wu, Y. (2020). SpecAugment on large scale datasets. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 6897&#x2013;6883.</Citation></Reference><Reference><Citation>Riedhammer, K. , Stemmer, G. , Haderlein, T. , Schuster, M. , Rosanowski, F. , N&#xf6;th, E. , &amp; Maier, A. (2007). Towards robust automatic evaluation of pathologic telephone speech. 2007 IEEE Workshop on Automatic Speech Recognition and Understanding, Proceedings, 717&#x2013;722. https://doi.org/10.1109/asru.2007.4430200</Citation></Reference><Reference><Citation>Robin, X. , Turck, N. , Hainard, A. , Tiberti, N. , Lisacek, F. , Sanchez, J. C. , &amp; M&#xfc;ller, M. (2011). pROC: An open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1), 1&#x2013;8. https://doi.org/10.1186/1471-2105-12-77</Citation><ArticleIdList><ArticleId IdType="pmc">PMC3068975</ArticleId><ArticleId IdType="pubmed">21414208</ArticleId></ArticleIdList></Reference><Reference><Citation>Rong, P. , Yunusova, Y. , &amp; Green, J. R. (2015). Speech intelligibility decline in individuals with fast and slow rates of ALS progression. Interspeech 2015 Conference Proceedings, 2967&#x2013;2971.</Citation></Reference><Reference><Citation>Rong, P. , Yunusova, Y. , Wang, J. , &amp; Green, J. R. (2015). Predicting early bulbar decline in amyotrophic lateral sclerosis: A speech subsystem approach. Behavioural Neurology, 2015, Article 183027. https://doi.org/10.1155/2015/183027</Citation><ArticleIdList><ArticleId IdType="pmc">PMC4468279</ArticleId><ArticleId IdType="pubmed">26136624</ArticleId></ArticleIdList></Reference><Reference><Citation>Rowe, H. P. , Gutz, S. E. , Maffei, M. F. , &amp; Green, J. R. (2020). Acoustic-based articulatory phenotypes of amyotrophic lateral sclerosis and Parkinson's disease: Towards an interpretable, hypothesis-driven framework of motor control. Interspeech 2020 Conference Proceedings, 4816&#x2013;4820.</Citation></Reference><Reference><Citation>Stipancic, K. L. , Palmer, K. M. , Rowe, H. P. , Yunusova, Y. , Berry, J. D. , &amp; Green, J. R. (2021). &#x201c;You say severe, I say mild&#x201d;: Toward an empirical classification of dysarthria severity. Journal of Speech, Language, and Hearing Research, 64(12), 4718&#x2013;4735. https://doi.org/10.1044/2021_JSLHR-21-00197</Citation><ArticleIdList><ArticleId IdType="pmc">PMC9150682</ArticleId><ArticleId IdType="pubmed">34762814</ArticleId></ArticleIdList></Reference><Reference><Citation>Stipancic, K. L. , Yunusova, Y. , Berry, J. D. , &amp; Green, J. R. (2018). Minimally detectable change and minimal clinically important difference of a decline in sentence intelligibility and speaking rate for individuals with amyotrophic lateral sclerosis. Journal of Speech, Language, and Hearing Research, 61(11), 2757&#x2013;2771. https://doi.org/10.1044/2018_JSLHR-S-17-0366</Citation><ArticleIdList><ArticleId IdType="pmc">PMC6693567</ArticleId><ArticleId IdType="pubmed">30383220</ArticleId></ArticleIdList></Reference><Reference><Citation>Stratford, P. W. , &amp; Riddle, D. L. (2012). When minimal detectable change exceeds a diagnostic test&#x2013;based threshold change value for an outcome measure: Resolving the conflict. Physical Therapy, 92(10), 1338&#x2013;1347. https://doi.org/10.2522/ptj.20120002</Citation><ArticleIdList><ArticleId IdType="pubmed">22767887</ArticleId></ArticleIdList></Reference><Reference><Citation>Sussman, J. E. , &amp; Tjaden, K. (2012). Perceptual measures of speech from individuals with Parkinson's disease and multiple sclerosis: Intelligibility and beyond. Journal of Speech, Language, and Hearing Research, 55(4), 1208&#x2013;1219. https://doi.org/10.1044/1092-4388(2011/11-0048)</Citation><ArticleIdList><ArticleId IdType="pmc">PMC5564315</ArticleId><ArticleId IdType="pubmed">22232396</ArticleId></ArticleIdList></Reference><Reference><Citation>

Therneau, T.
, &amp; 
Atkinson, B.
 (2019). rpart: Recursive partitioning and regression trees. R package version, 4, 1&#x2013;15. 
https://CRAN.R-project.org/package=rpart

</Citation></Reference><Reference><Citation>Tjaden, K. , &amp; Liss, J. (1995). The role of listener familiarity in the perception of dysarthric speech. Clinical Linguistics and Phonetics, 9(2), 139&#x2013;154. https://doi.org/10.3109/02699209508985329</Citation></Reference><Reference><Citation>Tjaden, K. , &amp; Watling, E. (2003). Characteristics of diadochokinesis in multiple sclerosis and Parkinson's disease. Folia Phoniatrica et Logopaedica, 55(5), 241&#x2013;259. https://doi.org/10.1159/000072155</Citation><ArticleIdList><ArticleId IdType="pubmed">12931058</ArticleId></ArticleIdList></Reference><Reference><Citation>Tomik, B. , &amp; Guiloff, R. J. (2010). Dysarthria in amyotrophic lateral sclerosis: A review. Amyotrophic Lateral Sclerosis, 11(1&#x2013;2), 4&#x2013;15. https://doi.org/10.3109/17482960802379004</Citation><ArticleIdList><ArticleId IdType="pubmed">20184513</ArticleId></ArticleIdList></Reference><Reference><Citation>Toth, L. , Hoffmann, I. , Gosztolya, G. , Vincze, V. , Szatloczki, G. , Banreti, Z. , Pakaski, M. , &amp; Kalman, J. (2018). A speech recognition-based solution for the automatic detection of mild cognitive impairment from spontaneous speech. Current Alzheimer Research, 15(2), 130&#x2013;138. https://doi.org/10.2174/1567205014666171121114930</Citation><ArticleIdList><ArticleId IdType="pmc">PMC5815089</ArticleId><ArticleId IdType="pubmed">29165085</ArticleId></ArticleIdList></Reference><Reference><Citation>Tu, M. , Wisler, A. , Berisha, V. , &amp; Liss, J. M. (2016). The relationship between perceptual disturbances in dysarthric speech and automatic speech recognition performance. The Journal of the Acoustical Society of America, 140(5), EL416&#x2013;EL422. https://doi.org/10.1121/1.4967208</Citation><ArticleIdList><ArticleId IdType="pmc">PMC6909999</ArticleId><ArticleId IdType="pubmed">27908075</ArticleId></ArticleIdList></Reference><Reference><Citation>V&#xe1;squez-Correa, J. C. , Orozco-Arroyave, J. R. , Bocklet, T. , &amp; N&#xf6;th, E. (2018). Towards an automatic evaluation of the dysarthria level of patients with Parkinson's disease. Journal of Communication Disorders, 76, 21&#x2013;36. https://doi.org/10.1016/j.jcomdis.2018.08.002</Citation><ArticleIdList><ArticleId IdType="pubmed">30149241</ArticleId></ArticleIdList></Reference><Reference><Citation>Weismer, G. , Jeng, J.-Y. , Laures, J. S. , Kent, R. D. , &amp; Kent, J. F. (2001). Acoustic and intelligibility characteristics of sentence production in neurogenic speech disorders. Folia Phoniatrica et Logopaedica, 53(1), 1&#x2013;18. https://doi.org/10.1159/000052649</Citation><ArticleIdList><ArticleId IdType="pubmed">11125256</ArticleId></ArticleIdList></Reference><Reference><Citation>Yorkston, K. , Beukelman, D. , &amp; Hakel, M. (2007). Speech Intelligibility Test (SIT) for Windows. Institute for Rehabilitation Science and Engineering at Madonna Rehabilitation Hospital.</Citation></Reference><Reference><Citation>

Zhang, A.
 (2017). Speech recognition (Version 3.8) [Software]
. 
https://github.com/Uberi/speech_recognition

</Citation></Reference><Reference><Citation>Ziegler, W. (2002). Task-related factors in oral motor control: Speech and oral diadochokinesis in dysarthria and apraxia of speech. Brain and Language, 80(3), 556&#x2013;575. https://doi.org/10.1006/brln.2001.2614</Citation><ArticleIdList><ArticleId IdType="pubmed">11896657</ArticleId></ArticleIdList></Reference></ReferenceList></PubmedData></PubmedArticle></PubmedArticleSet>