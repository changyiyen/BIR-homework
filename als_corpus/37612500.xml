<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Curated"><PMID Version="1">37612500</PMID><DateCompleted><Year>2023</Year><Month>09</Month><Day>14</Day></DateCompleted><DateRevised><Year>2023</Year><Month>10</Month><Day>26</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1476-4687</ISSN><JournalIssue CitedMedium="Internet"><Volume>620</Volume><Issue>7976</Issue><PubDate><Year>2023</Year><Month>Aug</Month></PubDate></JournalIssue><Title>Nature</Title><ISOAbbreviation>Nature</ISOAbbreviation></Journal><ArticleTitle>A high-performance speech neuroprosthesis.</ArticleTitle><Pagination><StartPage>1031</StartPage><EndPage>1036</EndPage><MedlinePgn>1031-1036</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1038/s41586-023-06377-x</ELocationID><Abstract><AbstractText>Speech brain-computer interfaces (BCIs) have the potential to restore rapid communication to people with paralysis by decoding neural activity evoked by attempted speech into text<sup>1,2</sup> or sound<sup>3,4</sup>. Early demonstrations, although promising, have not yet achieved accuracies sufficiently high for communication of unconstrained sentences from a large vocabulary<sup>1-7</sup>. Here we demonstrate a speech-to-text BCI that records spiking activity from intracortical microelectrode arrays. Enabled by these high-resolution recordings, our study participant-who can no longer speak intelligibly owing to amyotrophic lateral sclerosis-achieved a 9.1% word error rate on a 50-word vocabulary (2.7&#x2009;times fewer errors than the previous state-of-the-art speech BCI<sup>2</sup>) and a 23.8% word error rate on a 125,000-word vocabulary (the first successful demonstration, to our knowledge, of large-vocabulary decoding). Our participant's attempted speech was decoded&#xa0; at 62&#x2009;words per minute, which is 3.4&#x2009;times as fast as the previous record<sup>8</sup> and begins to approach the speed of natural conversation (160&#x2009;words per minute<sup>9</sup>). Finally, we highlight two aspects of the neural code for speech that are encouraging for speech BCIs: spatially intermixed tuning to speech articulators that makes accurate decoding possible from only a small region of cortex, and a detailed articulatory representation of phonemes that persists years after paralysis. These results show a feasible path forward for&#xa0;restoring rapid communication to people with paralysis who can no longer speak.</AbstractText><CopyrightInformation>&#xa9; 2023. The Author(s).</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y" EqualContrib="Y"><LastName>Willett</LastName><ForeName>Francis R</ForeName><Initials>FR</Initials><Identifier Source="ORCID">0000-0002-2652-8511</Identifier><AffiliationInfo><Affiliation>Howard Hughes Medical Institute at Stanford University, Stanford, CA, USA. willett2@gmail.com.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y" EqualContrib="Y"><LastName>Kunz</LastName><ForeName>Erin M</ForeName><Initials>EM</Initials><AffiliationInfo><Affiliation>Department of Electrical Engineering, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Wu Tsai Neurosciences Institute, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y" EqualContrib="Y"><LastName>Fan</LastName><ForeName>Chaofei</ForeName><Initials>C</Initials><AffiliationInfo><Affiliation>Department of Computer Science, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Avansino</LastName><ForeName>Donald T</ForeName><Initials>DT</Initials><AffiliationInfo><Affiliation>Howard Hughes Medical Institute at Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Wilson</LastName><ForeName>Guy H</ForeName><Initials>GH</Initials><Identifier Source="ORCID">0000-0003-0961-1994</Identifier><AffiliationInfo><Affiliation>Department of Neuroscience, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Choi</LastName><ForeName>Eun Young</ForeName><Initials>EY</Initials><Identifier Source="ORCID">0000-0003-3226-1486</Identifier><AffiliationInfo><Affiliation>Department of Neurosurgery, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Kamdar</LastName><ForeName>Foram</ForeName><Initials>F</Initials><AffiliationInfo><Affiliation>Department of Neurosurgery, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Glasser</LastName><ForeName>Matthew F</ForeName><Initials>MF</Initials><AffiliationInfo><Affiliation>Department of Neuroscience, Washington University in St. Louis, St. Louis, MO, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Radiology, Washington University in St. Louis, St. Louis, MO, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Hochberg</LastName><ForeName>Leigh R</ForeName><Initials>LR</Initials><Identifier Source="ORCID">0000-0003-0261-2273</Identifier><AffiliationInfo><Affiliation>VA RR&amp;D Center for Neurorestoration and Neurotechnology, Rehabilitation R&amp;D Service, Providence VA Medical Center, Providence, RI, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Center for Neurotechnology and Neurorecovery, Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Druckmann</LastName><ForeName>Shaul</ForeName><Initials>S</Initials><Identifier Source="ORCID">0000-0003-0068-3377</Identifier><AffiliationInfo><Affiliation>Department of Neurobiology, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Shenoy</LastName><ForeName>Krishna V</ForeName><Initials>KV</Initials><AffiliationInfo><Affiliation>Howard Hughes Medical Institute at Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Electrical Engineering, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Wu Tsai Neurosciences Institute, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Neurobiology, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Bioengineering, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Bio-X Program, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Henderson</LastName><ForeName>Jaimie M</ForeName><Initials>JM</Initials><Identifier Source="ORCID">0000-0002-3276-2267</Identifier><AffiliationInfo><Affiliation>Wu Tsai Neurosciences Institute, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Neurosurgery, Stanford University, Stanford, CA, USA.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><GrantList CompleteYN="Y"><Grant><GrantID>U01 DC017844</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant><Grant><GrantID>U01 DC019430</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant></GrantList><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2023</Year><Month>08</Month><Day>23</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>Nature</MedlineTA><NlmUniqueID>0410462</NlmUniqueID><ISSNLinking>0028-0836</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><CommentsCorrectionsList><CommentsCorrections RefType="UpdateOf"><RefSource>bioRxiv. 2023 Apr 25;:</RefSource><PMID Version="1">36711591</PMID></CommentsCorrections><CommentsCorrections RefType="CommentIn"><RefSource>Nat Rev Neurosci. 2023 Nov;24(11):653</RefSource><PMID Version="1">37740095</PMID></CommentsCorrections></CommentsCorrectionsList><MeshHeadingList><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="N">Amyotrophic Lateral Sclerosis</DescriptorName><QualifierName UI="Q000503" MajorTopicYN="N">physiopathology</QualifierName><QualifierName UI="Q000534" MajorTopicYN="N">rehabilitation</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D062207" MajorTopicYN="Y">Brain-Computer Interfaces</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D002540" MajorTopicYN="N">Cerebral Cortex</DescriptorName><QualifierName UI="Q000502" MajorTopicYN="N">physiology</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D008839" MajorTopicYN="N">Microelectrodes</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D010243" MajorTopicYN="Y">Paralysis</DescriptorName><QualifierName UI="Q000503" MajorTopicYN="N">physiopathology</QualifierName><QualifierName UI="Q000534" MajorTopicYN="N">rehabilitation</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D013060" MajorTopicYN="Y">Speech</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D014825" MajorTopicYN="N">Vocabulary</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D058117" MajorTopicYN="Y">Neural Prostheses</DescriptorName></MeshHeading></MeshHeadingList><CoiStatement>The MGH Translational Research Center has a clinical research support agreement with Neuralink, Axoft, Reach Neuro and Synchron, for which L.R.H. provides consultative input. J.M.H. is a consultant for Neuralink, serves on the Medical Advisory Board of Enspire DBS and is a shareholder in Maplight Therapeutics. K.V.S. consults for Neuralink and CTRL-Labs (part of Facebook Reality Labs) and is on the scientific advisory boards of MIND-X, Inscopix and Heal. The remaining authors declare no competing interests.</CoiStatement></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2023</Year><Month>1</Month><Day>21</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2023</Year><Month>6</Month><Day>27</Day></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2023</Year><Month>9</Month><Day>1</Day><Hour>6</Hour><Minute>43</Minute></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2023</Year><Month>8</Month><Day>24</Day><Hour>0</Hour><Minute>42</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2023</Year><Month>8</Month><Day>23</Day><Hour>23</Hour><Minute>32</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">37612500</ArticleId><ArticleId IdType="pmc">PMC10468393</ArticleId><ArticleId IdType="doi">10.1038/s41586-023-06377-x</ArticleId><ArticleId IdType="pii">10.1038/s41586-023-06377-x</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Herff C, et al. Brain-to-text: decoding spoken phrases from phone representations in the brain. Front. Neurosci. 2015;9:217. doi: 10.3389/fnins.2015.00217.</Citation><ArticleIdList><ArticleId IdType="doi">10.3389/fnins.2015.00217</ArticleId><ArticleId IdType="pmc">PMC4464168</ArticleId><ArticleId IdType="pubmed">26124702</ArticleId></ArticleIdList></Reference><Reference><Citation>Moses DA, et al. Neuroprosthesis for decoding speech in a paralyzed person with anarthria. N. Engl. J. Med. 2021;385:217&#x2013;227. doi: 10.1056/NEJMoa2027540.</Citation><ArticleIdList><ArticleId IdType="doi">10.1056/NEJMoa2027540</ArticleId><ArticleId IdType="pmc">PMC8972947</ArticleId><ArticleId IdType="pubmed">34260835</ArticleId></ArticleIdList></Reference><Reference><Citation>Anumanchipalli GK, Chartier J, Chang EF. Speech synthesis from neural decoding of spoken sentences. Nature. 2019;568:493&#x2013;498. doi: 10.1038/s41586-019-1119-1.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41586-019-1119-1</ArticleId><ArticleId IdType="pmc">PMC9714519</ArticleId><ArticleId IdType="pubmed">31019317</ArticleId></ArticleIdList></Reference><Reference><Citation>Herff C, et al. Generating natural, intelligible speech from brain activity in motor, premotor, and inferior frontal cortices. Front. Neurosci. 2019;13:1267. doi: 10.3389/fnins.2019.01267.</Citation><ArticleIdList><ArticleId IdType="doi">10.3389/fnins.2019.01267</ArticleId><ArticleId IdType="pmc">PMC6882773</ArticleId><ArticleId IdType="pubmed">31824257</ArticleId></ArticleIdList></Reference><Reference><Citation>Kellis S, et al. Decoding spoken words using local field potentials recorded from the cortical surface. J. Neural Eng. 2010;7:056007. doi: 10.1088/1741-2560/7/5/056007.</Citation><ArticleIdList><ArticleId IdType="doi">10.1088/1741-2560/7/5/056007</ArticleId><ArticleId IdType="pmc">PMC2970568</ArticleId><ArticleId IdType="pubmed">20811093</ArticleId></ArticleIdList></Reference><Reference><Citation>Pei X, Barbour DL, Leuthardt EC, Schalk G. Decoding vowels and consonants in spoken and imagined words using electrocorticographic signals in humans. J. Neural Eng. 2011;8:046028. doi: 10.1088/1741-2560/8/4/046028.</Citation><ArticleIdList><ArticleId IdType="doi">10.1088/1741-2560/8/4/046028</ArticleId><ArticleId IdType="pmc">PMC3772685</ArticleId><ArticleId IdType="pubmed">21750369</ArticleId></ArticleIdList></Reference><Reference><Citation>Mugler EM, et al. Direct classification of all American English phonemes using signals from functional speech motor cortex. J. Neural Eng. 2014;11:035015. doi: 10.1088/1741-2560/11/3/035015.</Citation><ArticleIdList><ArticleId IdType="doi">10.1088/1741-2560/11/3/035015</ArticleId><ArticleId IdType="pmc">PMC4097188</ArticleId><ArticleId IdType="pubmed">24836588</ArticleId></ArticleIdList></Reference><Reference><Citation>Willett FR, Avansino DT, Hochberg LR, Henderson JM, Shenoy KV. High-performance brain-to-text communication via handwriting. Nature. 2021;593:249&#x2013;254. doi: 10.1038/s41586-021-03506-2.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41586-021-03506-2</ArticleId><ArticleId IdType="pmc">PMC8163299</ArticleId><ArticleId IdType="pubmed">33981047</ArticleId></ArticleIdList></Reference><Reference><Citation>Yuan, J., Liberman, M. &amp; Cieri, C. Towards an integrated understanding of speaking rate in conversation. In 9th Intl Conf. on Spoken Language Processing10.21437/Interspeech.2006-204 (2006).</Citation></Reference><Reference><Citation>Glasser MF, et al. A multi-modal parcellation of human cerebral cortex. Nature. 2016;536:171&#x2013;178. doi: 10.1038/nature18933.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/nature18933</ArticleId><ArticleId IdType="pmc">PMC4990127</ArticleId><ArticleId IdType="pubmed">27437579</ArticleId></ArticleIdList></Reference><Reference><Citation>Broca P. Nouvelle observation d&#x2019;aphemie produite par une lesion de la troisieme circonvolution frontale. Bull. Soc. Anat. 1861;2:398&#x2013;407.</Citation></Reference><Reference><Citation>Friederici AD, Gierhan SM. The language network. Curr. Opin. Neurobiol. 2013;23:250&#x2013;254. doi: 10.1016/j.conb.2012.10.002.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.conb.2012.10.002</ArticleId><ArticleId IdType="pubmed">23146876</ArticleId></ArticleIdList></Reference><Reference><Citation>Ardila A, Bernal B, Rosselli M. How localized are language brain areas? A review of Brodmann areas involvement in oral language. Arch. Clin. Neuropsychol. 2016;31:112&#x2013;122. doi: 10.1093/arclin/acv081.</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/arclin/acv081</ArticleId><ArticleId IdType="pubmed">26663825</ArticleId></ArticleIdList></Reference><Reference><Citation>Long MA, et al. Functional segregation of cortical regions underlying speech timing and articulation. Neuron. 2016;89:1187&#x2013;1193. doi: 10.1016/j.neuron.2016.01.032.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.neuron.2016.01.032</ArticleId><ArticleId IdType="pmc">PMC4833207</ArticleId><ArticleId IdType="pubmed">26924439</ArticleId></ArticleIdList></Reference><Reference><Citation>Tate MC, Herbet G, Moritz-Gasser S, Tate JE, Duffau H. Probabilistic map of critical functional regions of the human cerebral cortex: Broca&#x2019;s area revisited. Brain. 2014;137:2773&#x2013;2782. doi: 10.1093/brain/awu168.</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/brain/awu168</ArticleId><ArticleId IdType="pubmed">24970097</ArticleId></ArticleIdList></Reference><Reference><Citation>Flinker A, et al. Redefining the role of Broca&#x2019;s area in speech. Proc. Natl Acad. Sci. USA. 2015;112:2871&#x2013;2875. doi: 10.1073/pnas.1414491112.</Citation><ArticleIdList><ArticleId IdType="doi">10.1073/pnas.1414491112</ArticleId><ArticleId IdType="pmc">PMC4352780</ArticleId><ArticleId IdType="pubmed">25730850</ArticleId></ArticleIdList></Reference><Reference><Citation>Gajardo-Vidal A, et al. Damage to Broca&#x2019;s area does not contribute to long-term speech production outcome after stroke. Brain. 2021;144:817&#x2013;832. doi: 10.1093/brain/awaa460.</Citation><ArticleIdList><ArticleId IdType="doi">10.1093/brain/awaa460</ArticleId><ArticleId IdType="pmc">PMC8041045</ArticleId><ArticleId IdType="pubmed">33517378</ArticleId></ArticleIdList></Reference><Reference><Citation>Andrews JP, et al. Dissociation of Broca&#x2019;s area from Broca&#x2019;s aphasia in patients undergoing neurosurgical resections. J. Neurosurg. 2022;138:847&#x2013;857. doi: 10.3171/2022.6.JNS2297.</Citation><ArticleIdList><ArticleId IdType="doi">10.3171/2022.6.JNS2297</ArticleId><ArticleId IdType="pmc">PMC9899289</ArticleId><ArticleId IdType="pubmed">35932264</ArticleId></ArticleIdList></Reference><Reference><Citation>Bouchard KE, Mesgarani N, Johnson K, Chang EF. Functional organization of human sensorimotor cortex for speech articulation. Nature. 2013;495:327&#x2013;332. doi: 10.1038/nature11911.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/nature11911</ArticleId><ArticleId IdType="pmc">PMC3606666</ArticleId><ArticleId IdType="pubmed">23426266</ArticleId></ArticleIdList></Reference><Reference><Citation>Godfrey, J. J., Holliman, E. C. &amp; McDaniel, J. SWITCHBOARD: telephone speech corpus for research and development. In IEEE Intl Conf. on Acoustics, Speech, and Signal Processing10.1109/ICASSP.1992.225858 (IEEE, 1992).</Citation></Reference><Reference><Citation>Hinton G, et al. Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups. IEEE Signal Process. Mag. 2012;29:82&#x2013;97. doi: 10.1109/MSP.2012.2205597.</Citation><ArticleIdList><ArticleId IdType="doi">10.1109/MSP.2012.2205597</ArticleId></ArticleIdList></Reference><Reference><Citation>Graves, A., Mohamed, A. &amp; Hinton, G. Speech recognition with deep recurrent neural networks. In 2013 IEEE Intl Conf. on Acoustics, Speech and Signal Processing10.1109/ICASSP.2013.6638947 (IEEE, 2013).</Citation></Reference><Reference><Citation>Xiong, W. et al. The Microsoft 2017 Conversational Speech Recognition System. In 2018 IEEE Intl Conf. on Acoustics, Speech and Signal Processing (ICASSP) 10.1109/ICASSP.2018.8461870 (IEEE, 2018).</Citation></Reference><Reference><Citation>Dyer EL, et al. A cryptography-based approach for movement decoding. Nat. Biomed. Eng. 2017;1:967&#x2013;976. doi: 10.1038/s41551-017-0169-7.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41551-017-0169-7</ArticleId><ArticleId IdType="pmc">PMC8376093</ArticleId><ArticleId IdType="pubmed">31015712</ArticleId></ArticleIdList></Reference><Reference><Citation>Farshchian, A. et al. Adversarial domain adaptation for stable brain-machine interfaces. Preprint at 10.48550/arXiv.1810.00045 (2019).</Citation></Reference><Reference><Citation>Degenhart, A. D. et al. Stabilization of a brain&#x2013;computer interface via the alignment of low-dimensional spaces of neural activity. Nat. Biomed. Eng. 10.1038/s41551-020-0542-9 (2020).</Citation><ArticleIdList><ArticleId IdType="pmc">PMC7822646</ArticleId><ArticleId IdType="pubmed">32313100</ArticleId></ArticleIdList></Reference><Reference><Citation>Karpowicz, B. M. et al. Stabilizing brain-computer interfaces through alignment of latent dynamics. Preprint at bioRxiv10.1101/2022.04.06.487388 (2022).</Citation></Reference><Reference><Citation>Pels EGM, Aarnoutse EJ, Ramsey NF, Vansteensel MJ. Estimated prevalence of the target population for brain-computer interface neurotechnology in the Netherlands. Neurorehabil. Neural Repair. 2017;31:677&#x2013;685. doi: 10.1177/1545968317714577.</Citation><ArticleIdList><ArticleId IdType="doi">10.1177/1545968317714577</ArticleId><ArticleId IdType="pmc">PMC6396873</ArticleId><ArticleId IdType="pubmed">28639486</ArticleId></ArticleIdList></Reference><Reference><Citation>Pandarinath C, et al. High performance communication by people with paralysis using an intracortical brain-computer interface. eLife. 2017;6:e18554. doi: 10.7554/eLife.18554.</Citation><ArticleIdList><ArticleId IdType="doi">10.7554/eLife.18554</ArticleId><ArticleId IdType="pmc">PMC5319839</ArticleId><ArticleId IdType="pubmed">28220753</ArticleId></ArticleIdList></Reference><Reference><Citation>R&#xe4;ih&#xe4;, K.-J. &amp; Ovaska, S. An exploratory study of eye typing fundamentals: dwell time, text entry rate, errors, and workload. In Proc. SIGCHI Conf. on Human Factors in Computing Systems10.1145/2207676.2208711 (Association for Computing Machinery, 2012).</Citation></Reference><Reference><Citation>Sussillo D, Stavisky SD, Kao JC, Ryu SI, Shenoy KV. Making brain&#x2013;machine interfaces robust to future neural variability. Nat. Commun. 2016;7:13749. doi: 10.1038/ncomms13749.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/ncomms13749</ArticleId><ArticleId IdType="pmc">PMC5159828</ArticleId><ArticleId IdType="pubmed">27958268</ArticleId></ArticleIdList></Reference><Reference><Citation>Nurmikko A. Challenges for large-scale cortical interfaces. Neuron. 2020;108:259&#x2013;269. doi: 10.1016/j.neuron.2020.10.015.</Citation><ArticleIdList><ArticleId IdType="doi">10.1016/j.neuron.2020.10.015</ArticleId><ArticleId IdType="pubmed">33120022</ArticleId></ArticleIdList></Reference><Reference><Citation>V&#xe1;zquez-Guardado A, Yang Y, Bandodkar AJ, Rogers JA. Recent advances in neurotechnologies with broad potential for neuroscience research. Nat. Neurosci. 2020;23:1522&#x2013;1536. doi: 10.1038/s41593-020-00739-8.</Citation><ArticleIdList><ArticleId IdType="doi">10.1038/s41593-020-00739-8</ArticleId><ArticleId IdType="pubmed">33199897</ArticleId></ArticleIdList></Reference><Reference><Citation>Rubin DB, et al. Interim safety profile from the feasibility study of the BrainGate neural interface system. Neurology. 2023;100:e1177&#x2013;e1192. doi: 10.1212/WNL.0000000000201707.</Citation><ArticleIdList><ArticleId IdType="doi">10.1212/WNL.0000000000201707</ArticleId><ArticleId IdType="pmc">PMC10074470</ArticleId><ArticleId IdType="pubmed">36639237</ArticleId></ArticleIdList></Reference><Reference><Citation>Musk E. An integrated brain-machine interface platform with thousands of channels. J. Med. Internet Res. 2019;21:e16194. doi: 10.2196/16194.</Citation><ArticleIdList><ArticleId IdType="doi">10.2196/16194</ArticleId><ArticleId IdType="pmc">PMC6914248</ArticleId><ArticleId IdType="pubmed">31642810</ArticleId></ArticleIdList></Reference><Reference><Citation>Sahasrabuddhe K, et al. The Argo: a high channel count recording system for neural recording in vivo. J. Neural Eng. 2020 doi: 10.1088/1741-2552/abd0ce.</Citation><ArticleIdList><ArticleId IdType="doi">10.1088/1741-2552/abd0ce</ArticleId><ArticleId IdType="pmc">PMC8607496</ArticleId><ArticleId IdType="pubmed">33624614</ArticleId></ArticleIdList></Reference><Reference><Citation>He, Y. et al. Streaming end-to-end speech recognition for mobile devices. In ICASSP 2019 &#x2013; 2019 IEEE Intl Conf. on Acoustics, Speech and Signal Processing (ICASSP)10.1109/ICASSP.2019.8682336 (IEEE, 2019).</Citation></Reference><Reference><Citation>Aiello, A. A Phonetic Examination of California (UCSC Linguistics Research Center, 2010).</Citation></Reference></ReferenceList></PubmedData></PubmedArticle></PubmedArticleSet>