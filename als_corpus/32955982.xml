<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">32955982</PMID><DateCompleted><Year>2021</Year><Month>06</Month><Day>21</Day></DateCompleted><DateRevised><Year>2021</Year><Month>06</Month><Day>21</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1558-9102</ISSN><JournalIssue CitedMedium="Internet"><Volume>63</Volume><Issue>10</Issue><PubDate><Year>2020</Year><Month>Oct</Month><Day>16</Day></PubDate></JournalIssue><Title>Journal of speech, language, and hearing research : JSLHR</Title><ISOAbbreviation>J Speech Lang Hear Res</ISOAbbreviation></Journal><ArticleTitle>Comparison of Automated Acoustic Methods for Oral Diadochokinesis Assessment in Amyotrophic Lateral Sclerosis.</ArticleTitle><Pagination><StartPage>3453</StartPage><EndPage>3460</EndPage><MedlinePgn>3453-3460</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1044/2020_JSLHR-20-00109</ELocationID><Abstract><AbstractText>Purpose The purpose of this research note is to provide a performance comparison of available algorithms for the automated evaluation of oral diadochokinesis using speech samples from patients with amyotrophic lateral sclerosis (ALS). Method Four different algorithms based on a wide range of signal processing approaches were tested on a sequential motion rate /pa/-/ta/-/ka/ syllable repetition paradigm collected from 18 patients with ALS and 18 age- and gender-matched healthy controls (HCs). Results The best temporal detection of syllable position for a 10-ms tolerance value was achieved for ALS patients using a traditional signal processing approach based on a combination of filtering in the spectrogram, Bayesian detection, and polynomial thresholding with an accuracy rate of 74.4%, and for HCs using a deep learning approach with an accuracy rate of 87.6%. Compared to HCs, a slow diadochokinetic rate (<i>p</i> &lt; .001) and diadochokinetic irregularity (<i>p</i> &lt; .01) were detected in ALS patients. Conclusions The approaches using deep learning or multiple-step combinations of advanced signal processing methods provided a more robust solution to the estimation of oral DDK variables than did simpler approaches based on the rough segmentation of the signal envelope. The automated acoustic assessment of oral diadochokinesis shows excellent potential for monitoring bulbar disease progression in individuals with ALS.</AbstractText></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Novotny</LastName><ForeName>Michal</ForeName><Initials>M</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Melechovsky</LastName><ForeName>Jan</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Rozenstoks</LastName><ForeName>Kriss</ForeName><Initials>K</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Tykalova</LastName><ForeName>Tereza</ForeName><Initials>T</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Kryze</LastName><ForeName>Petr</ForeName><Initials>P</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Kanok</LastName><ForeName>Martin</ForeName><Initials>M</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Klempir</LastName><ForeName>Jiri</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Neurology and Centre of Clinical Neuroscience, First Faculty of Medicine, Charles University, Prague, Czech Republic.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Rusz</LastName><ForeName>Jan</ForeName><Initials>J</Initials><AffiliationInfo><Affiliation>Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic.</Affiliation></AffiliationInfo><AffiliationInfo><Affiliation>Department of Neurology and Centre of Clinical Neuroscience, First Faculty of Medicine, Charles University, Prague, Czech Republic.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType><PublicationType UI="D013485">Research Support, Non-U.S. Gov't</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2020</Year><Month>09</Month><Day>21</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>J Speech Lang Hear Res</MedlineTA><NlmUniqueID>9705610</NlmUniqueID><ISSNLinking>1092-4388</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000162" MajorTopicYN="N">Acoustics</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000465" MajorTopicYN="N">Algorithms</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="Y">Amyotrophic Lateral Sclerosis</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D001499" MajorTopicYN="N">Bayes Theorem</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D013060" MajorTopicYN="N">Speech</DescriptorName></MeshHeading></MeshHeadingList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="pubmed"><Year>2020</Year><Month>9</Month><Day>22</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2021</Year><Month>6</Month><Day>22</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2020</Year><Month>9</Month><Day>21</Day><Hour>17</Hour><Minute>12</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">32955982</ArticleId><ArticleId IdType="doi">10.1044/2020_JSLHR-20-00109</ArticleId></ArticleIdList></PubmedData></PubmedArticle></PubmedArticleSet>