<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM" IndexingMethod="Automated"><PMID Version="1">35817307</PMID><DateCompleted><Year>2022</Year><Month>08</Month><Day>08</Day></DateCompleted><DateRevised><Year>2022</Year><Month>10</Month><Day>18</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">1872-678X</ISSN><JournalIssue CitedMedium="Internet"><Volume>379</Volume><PubDate><Year>2022</Year><Month>Sep</Month><Day>01</Day></PubDate></JournalIssue><Title>Journal of neuroscience methods</Title><ISOAbbreviation>J Neurosci Methods</ISOAbbreviation></Journal><ArticleTitle>Visuo-auditory stimuli with semantic, temporal and spatial congruence for a P300-based BCI: An exploratory test with an ALS patient in a completely locked-in state.</ArticleTitle><Pagination><StartPage>109661</StartPage><MedlinePgn>109661</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1016/j.jneumeth.2022.109661</ELocationID><ELocationID EIdType="pii" ValidYN="Y">S0165-0270(22)00188-1</ELocationID><Abstract><AbstractText Label="BACKGROUND">Brain-computer interfaces (BCIs) are a promising tool for communication with completely locked-in state (CLIS) patients. Despite the great efforts already made by the BCI research community, the cases of success are still very few, very exploratory, limited in time, and based on simple 'yes/no' paradigms.</AbstractText><AbstractText Label="NEW METHOD">A P300-based BCI is proposed comparing two conditions, one corresponding to purely spatial auditory stimuli (AU-S) and the other corresponding to hybrid visual and spatial auditory stimuli (HVA-S). In the HVA-S condition, there is a semantic, temporal, and spatial congruence between visual and auditory stimuli. The stimuli comprise a lexicon of 7 written and spoken words. Spatial sounds are generated through the head-related transfer function. Given the good results obtained with 10 able-bodied participants, we investigated whether a patient entering CLIS could use the proposed BCI.</AbstractText><AbstractText Label="RESULTS">The able-bodied group achieved 71.3 % and 90.5 % online classification accuracy for the auditory and hybrid BCIs respectively, while the patient achieved 30 % and chance level accuracies, for the same conditions. Notwithstanding, the patient's event-related potentials (ERPs) showed statistical discrimination between target and non-target events in different time windows.</AbstractText><AbstractText Label="COMPARISON WITH EXISTING METHODS">The results of the control group compare favorably with the state-of-the-art, considering a 7-class BCI controlled visual-covertly and with auditory stimuli. The integration of visual and auditory stimuli has not been tested before with CLIS patients.</AbstractText><AbstractText Label="CONCLUSIONS">The semantic, temporal, and spatial congruence of the stimuli increased the performance of the control group, but not of the CLIS patient, which can be due to impaired attention and cognitive function. The patient's unique ERP patterns make interpretation difficult, requiring further tests/paradigms to decouple patients' responses at different levels (reflexive, perceptual, cognitive). The ERPs discrimination found indicates that a simplification of the proposed approaches may be feasible.</AbstractText><CopyrightInformation>Copyright &#xa9; 2022 Elsevier B.V. All rights reserved.</CopyrightInformation></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Pires</LastName><ForeName>Gabriel</ForeName><Initials>G</Initials><AffiliationInfo><Affiliation>Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal; Polytechnic Institute of Tomar, Department of Engineering, Tomar, Portugal. Electronic address: gpires@isr.uc.pt.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Barbosa</LastName><ForeName>Sara</ForeName><Initials>S</Initials><AffiliationInfo><Affiliation>Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Nunes</LastName><ForeName>Urbano J</ForeName><Initials>UJ</Initials><AffiliationInfo><Affiliation>Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal; University of Coimbra, Department of Electrical and Computer Engineering, Coimbra, Portugal.</Affiliation></AffiliationInfo></Author><Author ValidYN="Y"><LastName>Gon&#xe7;alves</LastName><ForeName>Edna</ForeName><Initials>E</Initials><AffiliationInfo><Affiliation>University Hospital Center of S&#xe3;o Jo&#xe3;o, Porto, Portugal.</Affiliation></AffiliationInfo></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType><PublicationType UI="D013485">Research Support, Non-U.S. Gov't</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2022</Year><Month>07</Month><Day>08</Day></ArticleDate></Article><MedlineJournalInfo><Country>Netherlands</Country><MedlineTA>J Neurosci Methods</MedlineTA><NlmUniqueID>7905558</NlmUniqueID><ISSNLinking>0165-0270</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="Y">Amyotrophic Lateral Sclerosis</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D062207" MajorTopicYN="Y">Brain-Computer Interfaces</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D004569" MajorTopicYN="N">Electroencephalography</DescriptorName><QualifierName UI="Q000379" MajorTopicYN="N">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D005071" MajorTopicYN="N">Evoked Potentials</DescriptorName><QualifierName UI="Q000502" MajorTopicYN="N">physiology</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D012660" MajorTopicYN="N">Semantics</DescriptorName></MeshHeading></MeshHeadingList><KeywordList Owner="NOTNLM"><Keyword MajorTopicYN="N">Amyotrophic lateral sclerosis (ALS)</Keyword><Keyword MajorTopicYN="N">Brain-computer interface (BCI)</Keyword><Keyword MajorTopicYN="N">Completely locked-in state (CLIS)</Keyword><Keyword MajorTopicYN="N">Gaze-independent</Keyword><Keyword MajorTopicYN="N">Head-Related-Transfer-Function</Keyword><Keyword MajorTopicYN="N">Hybrid Visual-Auditory stimuli</Keyword><Keyword MajorTopicYN="N">Meaningful natural spoken words</Keyword><Keyword MajorTopicYN="N">P300 event-related potential</Keyword><Keyword MajorTopicYN="N">Semantic, temporal and spatial congruence</Keyword></KeywordList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="received"><Year>2021</Year><Month>11</Month><Day>23</Day></PubMedPubDate><PubMedPubDate PubStatus="revised"><Year>2022</Year><Month>5</Month><Day>25</Day></PubMedPubDate><PubMedPubDate PubStatus="accepted"><Year>2022</Year><Month>7</Month><Day>4</Day></PubMedPubDate><PubMedPubDate PubStatus="pubmed"><Year>2022</Year><Month>7</Month><Day>12</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2022</Year><Month>8</Month><Day>9</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2022</Year><Month>7</Month><Day>11</Day><Hour>19</Hour><Minute>26</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">35817307</ArticleId><ArticleId IdType="doi">10.1016/j.jneumeth.2022.109661</ArticleId><ArticleId IdType="pii">S0165-0270(22)00188-1</ArticleId></ArticleIdList></PubmedData></PubmedArticle></PubmedArticleSet>