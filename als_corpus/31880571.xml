<?xml version="1.0" ?>
<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2023//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_230101.dtd">
<PubmedArticleSet>
<PubmedArticle><MedlineCitation Status="MEDLINE" Owner="NLM"><PMID Version="1">31880571</PMID><DateCompleted><Year>2021</Year><Month>05</Month><Day>07</Day></DateCompleted><DateRevised><Year>2021</Year><Month>05</Month><Day>07</Day></DateRevised><Article PubModel="Print-Electronic"><Journal><ISSN IssnType="Electronic">2168-2208</ISSN><JournalIssue CitedMedium="Internet"><Volume>24</Volume><Issue>10</Issue><PubDate><Year>2020</Year><Month>Oct</Month></PubDate></JournalIssue><Title>IEEE journal of biomedical and health informatics</Title><ISOAbbreviation>IEEE J Biomed Health Inform</ISOAbbreviation></Journal><ArticleTitle>Voice Conversion for Persons with Amyotrophic Lateral Sclerosis.</ArticleTitle><Pagination><StartPage>2942</StartPage><EndPage>2949</EndPage><MedlinePgn>2942-2949</MedlinePgn></Pagination><ELocationID EIdType="doi" ValidYN="Y">10.1109/JBHI.2019.2961844</ELocationID><Abstract><AbstractText>Amyotrophic lateral sclerosis (ALS) results in progressive paralysis of voluntary muscles throughout the body. As speech deteriorates, individuals rely on pre-programmed messages available on commercial speech generating devices to communicate using one of the generic electronic voices on the device. To replace these generic voices and restore vocal identity, our aim is to develop personalized voices for people with ALS via the approach of voice conversion. The task is challenging because very few people have large quantities of their premorbid healthy speech recorded. Therefore, we have to rely on small quantities of dysarthric speech concomitant with an individual's disease stage. Further, progressive fatigue prohibits acquisition of large speech datasets and individuals display a range of dysarthria severities resulting from breathing, voice, articulation, resonance, and prosody disturbances. As the first step to address these problems, we use healthy source speakers and propose the approach of combining a structured sparse spectral transform with multiple linear regression-based frequency warping prediction for spectral conversion, and interpolating the transformed spectral frames for speech rate modification. Our experimental data included four healthy source speakers from the ARCTIC dataset, and four target ALS speakers with mild to severe dysarthria, forming 16 speaker pairs. Subjective listening evaluations showed that on average, (i) the proposed approach improved speech intelligibility by about 80% over the target speakers' speech, (ii) the converted voice was 3 times more similar to the target speakers' speech than to the source speakers' speech, and (iii) the converted speech quality was close to the MOS scale "good" relative to the source speakers' speech being "excellent."</AbstractText></Abstract><AuthorList CompleteYN="Y"><Author ValidYN="Y"><LastName>Zhao</LastName><ForeName>Yunxin</ForeName><Initials>Y</Initials></Author><Author ValidYN="Y"><LastName>Kuruvilla-Dugdale</LastName><ForeName>Mili</ForeName><Initials>M</Initials></Author><Author ValidYN="Y"><LastName>Song</LastName><ForeName>Minguang</ForeName><Initials>M</Initials></Author></AuthorList><Language>eng</Language><GrantList CompleteYN="Y"><Grant><GrantID>R15 DC016383</GrantID><Acronym>DC</Acronym><Agency>NIDCD NIH HHS</Agency><Country>United States</Country></Grant></GrantList><PublicationTypeList><PublicationType UI="D016428">Journal Article</PublicationType><PublicationType UI="D052061">Research Support, N.I.H., Extramural</PublicationType><PublicationType UI="D013485">Research Support, Non-U.S. Gov't</PublicationType></PublicationTypeList><ArticleDate DateType="Electronic"><Year>2019</Year><Month>12</Month><Day>25</Day></ArticleDate></Article><MedlineJournalInfo><Country>United States</Country><MedlineTA>IEEE J Biomed Health Inform</MedlineTA><NlmUniqueID>101604520</NlmUniqueID><ISSNLinking>2168-2194</ISSNLinking></MedlineJournalInfo><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI="D000690" MajorTopicYN="N">Amyotrophic Lateral Sclerosis</DescriptorName><QualifierName UI="Q000503" MajorTopicYN="Y">physiopathology</QualifierName><QualifierName UI="Q000628" MajorTopicYN="N">therapy</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D003143" MajorTopicYN="Y">Communication Aids for Disabled</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D004401" MajorTopicYN="N">Dysarthria</DescriptorName><QualifierName UI="Q000503" MajorTopicYN="N">physiopathology</QualifierName><QualifierName UI="Q000628" MajorTopicYN="N">therapy</QualifierName></MeshHeading><MeshHeading><DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D012815" MajorTopicYN="Y">Signal Processing, Computer-Assisted</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI="D014831" MajorTopicYN="N">Voice</DescriptorName><QualifierName UI="Q000502" MajorTopicYN="Y">physiology</QualifierName></MeshHeading></MeshHeadingList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus="pubmed"><Year>2019</Year><Month>12</Month><Day>28</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="medline"><Year>2021</Year><Month>5</Month><Day>8</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus="entrez"><Year>2019</Year><Month>12</Month><Day>28</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate></History><PublicationStatus>ppublish</PublicationStatus><ArticleIdList><ArticleId IdType="pubmed">31880571</ArticleId><ArticleId IdType="mid">NIHMS1069315</ArticleId><ArticleId IdType="pmc">PMC7314644</ArticleId><ArticleId IdType="doi">10.1109/JBHI.2019.2961844</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>McKinley WO, Seel RT, and Hardman JT, &#x201c;Nontraumatic spinal cord injury: incidence, epidemiology, and functional outcome,&#x201d; Arch. of Phy. Med. and Rehabil, vol. 80, no. 6, pp. 619&#x2013;623, 1999.</Citation><ArticleIdList><ArticleId IdType="pubmed">10378485</ArticleId></ArticleIdList></Reference><Reference><Citation>Bunnell HT, Lilley J, Pennington C, Moyers B, and Polikoff J, &#x201c;The ModelTalker system,&#x201d; in Proc. the Blizzard Challenge Workshop, Kyoto, Japan, 2010.</Citation></Reference><Reference><Citation>Ball LJ et al., &#x201c;Eye gaze access of AAC technology for people with amyotrophic lateral sclerosis,&#x201d; J. of Med. Speech-Lang. Pathol, vol. 18, no. 3, pp. 11&#x2013;23, 2010.</Citation></Reference><Reference><Citation>Tamagishi J, Veaux C, King S, and Renals S, &#x201c;Speech synthesis technologies for individuals with vocal disabilities: voice banking and reconstruction,&#x201d; Acoust. Sci. &amp; Tech vol. 33, no. 1, pp. 1&#x2013;5, 2012.</Citation></Reference><Reference><Citation>Shen J et al., &#x201c;Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions,&#x201d; in Proc. Int. Conf. Acoust., Speech, Signal Process, pp. 4779&#x2013;4783, Calgary, Canada, 2018.</Citation></Reference><Reference><Citation>Toda T et al., &#x201c;The voice conversion challenge 2016,&#x201d; in Proc. Interspeech, pp. 1632&#x2013;1636, San Francisco, USA, 2016.</Citation></Reference><Reference><Citation>Lorenzo-Trueba J et al., &#x201c;The voice conversion challenge 2018: promoting development of parallel and nonparallel methods,&#x201d; in Proc. Speaker Odyssey 2018 The Speaker and Lang. Recognit. Workshop, pp. 195&#x2013;202, Les Sables d&#x2019;Olonne, France, 2018.</Citation></Reference><Reference><Citation>Doi H, Toda T, Nakamura K, Saruwatari H, and Shikano K, &#x201c;Alaryngeal speech enhancement based on one-to-many eigenvoice conversion,&#x201d; IEEE/ACM Trans. Audio, Speech, Lang. Process, vol. 22, no. 1, pp. 172&#x2013;183, 2014</Citation></Reference><Reference><Citation>Aihara R, Takashima R, Takiguchi T, and Ariki Y, &#x201c;Individuality-preserving voice conversion for articulation disorders based on nonnegative matrix factorization,&#x201d; in Proc. Int. Conf. Acoust., Speech, Signal Process, pp. 8037&#x2013;8040, Vancouver, Canada, 2013.</Citation></Reference><Reference><Citation>Kain A, Hosom J-P, Niu X, van Santen JPH, Fried-Oken M, and Staehely J, &#x201c;Improving the intelligibility of dysarthric speech,&#x201d; Speech Commun, vol. 49, no. 9, pp. 743&#x2013;759, 2007.</Citation></Reference><Reference><Citation>Chen L-W, Lee H-Y, and Tsao Y, &#x201c;Generative adversarial networks for unpaired voice transformation on impaired speech,&#x201d; in Proc. Interspeech, pp. 719&#x2013;723, Graz, Austria, 2019.</Citation></Reference><Reference><Citation>Zhao Y, Kuruvilla-Dugdale M, and Song M, &#x201c;Structured Sparse Spectral Transforms and Structural Measures for Voice Conversion,&#x201d; IEEE/ACM Trans. Audio, Speech, Lang. Process, vol. 26, no. 12, pp. 2267&#x2013;2276, 2018.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC6980218</ArticleId><ArticleId IdType="pubmed">31984214</ArticleId></ArticleIdList></Reference><Reference><Citation>Kawahara H, Morise M, Takahashi T, Nisimura R, Irino T, and Banno H, &#x201c;TANDEM STRAIGHT: a temporally stable power spectral representation for periodic signals and applications to interference-free spectrum, F0, and aperiodicity estimation,&#x201d; in Proc. Int. Conf. Acoust., Speech, Signal Process, pp. 3933&#x2013;3935, Las Vegas, USA, 2008.</Citation></Reference><Reference><Citation>Kominek J and Black AW, &#x201c;CMU ARCTIC database for speech synthesis,&#x201d; CMU-LTI-03-177, 2003.</Citation></Reference><Reference><Citation>Benisty H and Malah D, &#x201c;Voice conversion using GMM with enhanced global variance,&#x201d; in Proc. Interspeech, pp. 669&#x2013;672, Florence, Italy, 2011.</Citation></Reference><Reference><Citation>Yunusova Y et al., &#x201c;Profiling speech and pausing in amyotrophic lateral sclerosis (ALS) and frontotemporal dementia (FTD),&#x201d; PLoS One, vol. 11, no.1, pp. 1&#x2013;18, 2016.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC4720472</ArticleId><ArticleId IdType="pubmed">26789001</ArticleId></ArticleIdList></Reference><Reference><Citation>Lee DD and Seung HS, &#x201c;Algorithm for nonnegative matrix factorization,&#x201d; in Proc. Int. Conf. Neural Inf. Process. Syst, pp. 556&#x2013;562, Vancouver, Canada, 2001.</Citation></Reference><Reference><Citation>Oppenheim AV and Johnson DH, &#x201c;Discrete representation of signals,&#x201d; Proc. IEEE, vol. 60, no. 6, pp. 681&#x2013;691, 1972.</Citation></Reference><Reference><Citation>Wu Z, Virtanen T, Chng ES, and Li H, &#x201c;Exemplar based sparse representation with residue compensation for voice conversion,&#x201d; IEEE Trans. Audio, Speech, Lang. Process, vol. 22, no. 10, pp. 1506&#x2013;1521, 2014.</Citation></Reference><Reference><Citation>Ming H, Huang D, Xie L, Zhang S, Dong M, and Li H, &#x201c;Exemplar-based sparse representation on timbre and prosody for voice conversion,&#x201d; in Proc. Int. Conf. Acoust., Speech, Signal Process, pp. 5175&#x2013;5179, Shanghai, China, 2016.</Citation></Reference><Reference><Citation>Alpaydin E, Introduction to Machine Learning, MIT Press, 2004.</Citation></Reference><Reference><Citation>Valbret H, Moulines E, Tubach JP, &#x201c;Voice transformation using PSOLA techniques,&#x201d; in Proc. Int. Conf. Acoust., Speech, Signal Process, pp. I-145&#x2013;149, San Francisco, USA, 1992.</Citation></Reference><Reference><Citation>Stylianous Y, Cappe O, and Moulines E, &#x201c;Continuous probabilistic transform for voice conversion,&#x201d; IEEE Trans. Speech Audio Process, vol. 6, no. 2, pp. 131&#x2013;142, 1998.</Citation></Reference><Reference><Citation>Rabiner L and Juang B-H, Fundamental of Speech Recognition, Prentice Hall, 1993.</Citation></Reference><Reference><Citation>  http://htk.eng.cam.ac.uk/</Citation></Reference><Reference><Citation>Richard R, &#x201c;Concepts and Applications of Inferential Statistics,&#x201d; http://vassarstats.net/textbook/, 2011.</Citation></Reference><Reference><Citation>Levenshtein VI, &#x201c;Binary codes capable of correcting deletions, insertions and reversals,&#x201d; Sov. Phys., Doklady, vol. 10, no. 8, pp. 707&#x2013;710, 1966.</Citation></Reference><Reference><Citation>Smiljani&#x107; R and Bradlow AR, &#x201c;Speaking and hearing clearly: Talker and listener factors in speaking style changes,&#x201d; Lang. Ling. Compass, vol. 3, no. 1, pp. 236&#x2013;264, 2009.</Citation><ArticleIdList><ArticleId IdType="pmc">PMC2747755</ArticleId><ArticleId IdType="pubmed">20046964</ArticleId></ArticleIdList></Reference><Reference><Citation>Tamamori A, Hayashi T, Kobayashi K, Takeda K, Toda T, &#x201c;Speaker-dependent WaveNet vocoder,&#x201d; in Proc. Interspeech, pp. 1118&#x2013;1122, Stockholm, Sweden, 2017.</Citation></Reference><Reference><Citation>Sheard C, Adams RD, and Davis PJ, &#x201c;Reliability and agreement of ratings of ataxic dysarthric speech samples with varying intelligibility,&#x201d; J. Speech Hearing Res, vol. 34, no. 2, 285&#x2013;293, 1991.</Citation><ArticleIdList><ArticleId IdType="pubmed">2046353</ArticleId></ArticleIdList></Reference></ReferenceList></PubmedData></PubmedArticle></PubmedArticleSet>